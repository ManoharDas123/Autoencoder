# -*- coding: utf-8 -*-
"""AutoEncoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IAitQvDJcXJ13dOYN-Nd0Q53tFja0Ii8
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

# Download and Load MNIST dataset
transform = transforms.ToTensor() # Transform Image into pytorch tensor
mnist_data = datasets.MNIST(root='./data,', train=True, download=True, transform=transform)
data_loader = torch.utils.data.DataLoader(dataset=mnist_data, batch_size=64, shuffle=True)

# Print the minimum and maximum size of dataset
dataiter = iter(data_loader)
images, labels = next(dataiter)
print(torch.min(images), torch.max(images))

# Build Linear AutoEncoder Model where we will reduce the size of the image.

class Autoencoder_Linear(nn.Module):
  def __init__(self):
    # N, 784
    super().__init__()
    self.encoder =nn.Sequential(
        nn.Linear(28*28, 128), # Reduce size of image N,784 -> N,128
        nn.ReLU(),
        nn.Linear(128,64),
        nn.ReLU(),
        nn.Linear(64,12),
        nn.ReLU(),
        nn.Linear(12,3) # Reduce our Image on size-> N,3
    )

    self.decoder =nn.Sequential(
        nn.Linear(3, 12), 
        nn.ReLU(),
        nn.Linear(12, 64),
        nn.ReLU(),
        nn.Linear(64, 128),
        nn.ReLU(),
        nn.Linear(128,28*28),
        nn.Sigmoid()  # Get back original size of image N,3 -> N,784
    )
  
  def forward(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

# Note: [-1, 1] -> nn.Tanh

#Convolutional Neural Network Autoencoder

class Autoencoder(nn.Module):
  def __init__(self):
    # N, 1, 28,28
    super().__init__()
    self.encoder =nn.Sequential(
        nn.Conv2d(1,16,3, stride=2, padding=1), # N, 16, 14, 14 (16 is output channel)
        nn.ReLU(),
        nn.Conv2d(16,32,3, stride=2, padding=1), # N, 32, 7, 7
        nn.ReLU(),
        nn.Conv2d(32,64,7) # N, 64, 1, 1 (here output channel is of size 64)
    )

    self.decoder =nn.Sequential(
        nn.ConvTranspose2d(64,32,7),  # N, 32, 7,7 
        nn.ReLU(),
        nn.ConvTranspose2d(32,16,3, stride=2, padding=1, output_padding=1), # N, 16, 14, 14
        nn.ReLU(),
        nn.ConvTranspose2d(16,1,3, stride=2, padding=1, output_padding=1), #N, 1, 28,28)
        nn.Sigmoid()
    )
  
  def forward(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

# Call Model and calculate Loss function then optimize the Model parameter

model = Autoencoder()
criterion = nn.MSELoss() # Loss Function
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5) #optimizer it will optimize the parameter

num_epochs = 10
outputs = []
for epoch in range(num_epochs):
  for (img, _) in data_loader:
    # img = img.reshape(-1, 28*28)
    recon = model(img)
    loss = criterion(recon,img)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  
  print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
  outputs.append((epoch, img, recon))